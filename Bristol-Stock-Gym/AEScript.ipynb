{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "from torch import nn \n",
    "torch.set_default_tensor_type('torch.DoubleTensor')\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as Functional\n",
    "from torch.autograd import Variable\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "from AE import Autoencoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dims = 9*5\n",
    "model = Autoencoder(input_dims = 9*5, l1_size = 32, l2_size = 16, l3_size = 8)#.cuda()\n",
    "\n",
    "\n",
    "dataset = np.load(\"Data/unnormalized_data.npy\")\n",
    "row,cols,num_images = dataset.shape\n",
    "lobs = []\n",
    "for i in range(num_images):\n",
    "    lob = dataset[:,:,i]\n",
    "    lob = lob.flatten()\n",
    "    lobs.append(lob)\n",
    "    \n",
    "len_data = len(lobs)\n",
    "train_len = int(0.7*len_data)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[981.         394.         957.         170.         414.\n   1.           1.           1.           1.           1.\n  70.          70.          70.          70.          70.\n   1.           1.           1.           1.           1.\n   0.           0.           0.           0.           0.\n   0.           0.           0.           0.           0.\n   0.           0.           0.           0.           0.\n   0.           0.           0.           0.           0.\n   1.9          1.91666667   1.93333333   1.95         1.96666667].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-18d7b612a123>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mminmax_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf_minmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminmax_scale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtrainloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_minmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         X = check_array(X, copy=self.copy, dtype=FLOAT_DTYPES,\n\u001b[0;32m--> 412\u001b[0;31m                         force_all_finite=\"allow-nan\")\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    538\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[981.         394.         957.         170.         414.\n   1.           1.           1.           1.           1.\n  70.          70.          70.          70.          70.\n   1.           1.           1.           1.           1.\n   0.           0.           0.           0.           0.\n   0.           0.           0.           0.           0.\n   0.           0.           0.           0.           0.\n   0.           0.           0.           0.           0.\n   1.9          1.91666667   1.93333333   1.95         1.96666667].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "minmax_scale = preprocessing.MinMaxScaler().fit(lobs)\n",
    "df_minmax = minmax_scale.transform(lobs)\n",
    "trainloader = DataLoader(df_minmax, batch_size = 256, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3, weight_decay = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/100], Train loss:0.0238\n",
      "epoch [2/100], Train loss:0.0072\n",
      "epoch [3/100], Train loss:0.0046\n",
      "epoch [4/100], Train loss:0.0043\n",
      "epoch [5/100], Train loss:0.0042\n",
      "epoch [6/100], Train loss:0.0041\n",
      "epoch [7/100], Train loss:0.0038\n",
      "epoch [8/100], Train loss:0.0035\n",
      "epoch [9/100], Train loss:0.0035\n",
      "epoch [10/100], Train loss:0.0034\n",
      "epoch [11/100], Train loss:0.0033\n",
      "epoch [12/100], Train loss:0.0032\n",
      "epoch [13/100], Train loss:0.0031\n",
      "epoch [14/100], Train loss:0.0031\n",
      "epoch [15/100], Train loss:0.0030\n",
      "epoch [16/100], Train loss:0.0027\n",
      "epoch [17/100], Train loss:0.0027\n",
      "epoch [18/100], Train loss:0.0027\n",
      "epoch [19/100], Train loss:0.0026\n",
      "epoch [20/100], Train loss:0.0026\n",
      "epoch [21/100], Train loss:0.0025\n",
      "epoch [22/100], Train loss:0.0024\n",
      "epoch [23/100], Train loss:0.0023\n",
      "epoch [24/100], Train loss:0.0023\n",
      "epoch [25/100], Train loss:0.0023\n",
      "epoch [26/100], Train loss:0.0023\n",
      "epoch [27/100], Train loss:0.0023\n",
      "epoch [28/100], Train loss:0.0022\n",
      "epoch [29/100], Train loss:0.0022\n",
      "epoch [30/100], Train loss:0.0022\n",
      "epoch [31/100], Train loss:0.0022\n",
      "epoch [32/100], Train loss:0.0022\n",
      "epoch [33/100], Train loss:0.0022\n",
      "epoch [34/100], Train loss:0.0022\n",
      "epoch [35/100], Train loss:0.0022\n",
      "epoch [36/100], Train loss:0.0022\n",
      "epoch [37/100], Train loss:0.0022\n",
      "epoch [38/100], Train loss:0.0022\n",
      "epoch [39/100], Train loss:0.0022\n",
      "epoch [40/100], Train loss:0.0022\n",
      "epoch [41/100], Train loss:0.0022\n",
      "epoch [42/100], Train loss:0.0022\n",
      "epoch [43/100], Train loss:0.0022\n",
      "epoch [44/100], Train loss:0.0022\n",
      "epoch [45/100], Train loss:0.0022\n",
      "epoch [46/100], Train loss:0.0022\n",
      "epoch [47/100], Train loss:0.0022\n",
      "epoch [48/100], Train loss:0.0022\n",
      "epoch [49/100], Train loss:0.0022\n",
      "epoch [50/100], Train loss:0.0022\n",
      "epoch [51/100], Train loss:0.0022\n",
      "epoch [52/100], Train loss:0.0022\n",
      "epoch [53/100], Train loss:0.0022\n",
      "epoch [54/100], Train loss:0.0022\n",
      "epoch [55/100], Train loss:0.0021\n",
      "epoch [56/100], Train loss:0.0021\n",
      "epoch [57/100], Train loss:0.0021\n",
      "epoch [58/100], Train loss:0.0021\n",
      "epoch [59/100], Train loss:0.0021\n",
      "epoch [60/100], Train loss:0.0021\n",
      "epoch [61/100], Train loss:0.0021\n",
      "epoch [62/100], Train loss:0.0021\n",
      "epoch [63/100], Train loss:0.0021\n",
      "epoch [64/100], Train loss:0.0021\n",
      "epoch [65/100], Train loss:0.0021\n",
      "epoch [66/100], Train loss:0.0021\n",
      "epoch [67/100], Train loss:0.0021\n",
      "epoch [68/100], Train loss:0.0021\n",
      "epoch [69/100], Train loss:0.0021\n",
      "epoch [70/100], Train loss:0.0021\n",
      "epoch [71/100], Train loss:0.0021\n",
      "epoch [72/100], Train loss:0.0021\n",
      "epoch [73/100], Train loss:0.0021\n",
      "epoch [74/100], Train loss:0.0021\n",
      "epoch [75/100], Train loss:0.0021\n",
      "epoch [76/100], Train loss:0.0021\n",
      "epoch [77/100], Train loss:0.0021\n",
      "epoch [78/100], Train loss:0.0021\n",
      "epoch [79/100], Train loss:0.0021\n",
      "epoch [80/100], Train loss:0.0021\n",
      "epoch [81/100], Train loss:0.0021\n",
      "epoch [82/100], Train loss:0.0021\n",
      "epoch [83/100], Train loss:0.0021\n",
      "epoch [84/100], Train loss:0.0021\n",
      "epoch [85/100], Train loss:0.0021\n",
      "epoch [86/100], Train loss:0.0021\n",
      "epoch [87/100], Train loss:0.0021\n",
      "epoch [88/100], Train loss:0.0021\n",
      "epoch [89/100], Train loss:0.0021\n",
      "epoch [90/100], Train loss:0.0021\n",
      "epoch [91/100], Train loss:0.0021\n",
      "epoch [92/100], Train loss:0.0021\n",
      "epoch [93/100], Train loss:0.0021\n",
      "epoch [94/100], Train loss:0.0021\n",
      "epoch [95/100], Train loss:0.0021\n",
      "epoch [96/100], Train loss:0.0021\n",
      "epoch [97/100], Train loss:0.0021\n",
      "epoch [98/100], Train loss:0.0021\n",
      "epoch [99/100], Train loss:0.0021\n",
      "epoch [100/100], Train loss:0.0021\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for data in trainloader:    \n",
    "        lob = Variable(data)#.cuda()\n",
    "        #===============forward==================\n",
    "        output = model(lob)    \n",
    "        loss = criterion(output, lob)\n",
    "        #===============backward=================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #===============log======================\n",
    "        running_loss += loss.item()\n",
    "    loss = running_loss / len(trainloader)\n",
    "    print('epoch [{}/{}], Train loss:{:.4f}'\n",
    "        .format(epoch + 1, epochs, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[125.         125.         125.         118.         125.\n",
      "   1.           1.           1.           1.           1.\n",
      "  99.          99.          99.          99.          99.\n",
      "   1.           1.           1.           1.           1.\n",
      " 128.         128.         128.         125.         128.\n",
      "   1.           1.           1.           1.           1.\n",
      "  88.          51.          68.          78.          94.\n",
      "   1.           1.           1.           1.           1.\n",
      " 385.5        385.51666667 385.53333333 385.55       385.56666667]\n",
      "[[113.09006153 111.68890654 111.41951206 112.08268816 112.35462376\n",
      "    0.99376467   0.99014479   0.98862873   0.99542708   0.9959733\n",
      "   96.99039436  97.28525172  96.63131641  97.07149858  96.68620642\n",
      "    1.02830081   1.00813816   1.0405895    1.0295236    1.0321383\n",
      "  119.78622725 117.80931134 116.40433701 118.42424204 117.62183531\n",
      "    0.99802982   1.00329973   0.98852445   0.99684206   0.99851665\n",
      "   82.35505271  76.96618928  70.20838663  79.28366144  78.46958133\n",
      "    0.97786178   0.98123206   0.99818006   0.98218158   0.96627851\n",
      "  384.40410587 384.49070643 384.55312378 384.62433321 384.64059019]]\n"
     ]
    }
   ],
   "source": [
    "data = lobs[80000]\n",
    "print(data)\n",
    "data= data.reshape(1,-1)\n",
    "\n",
    "data = minmax_scale.transform(data)\n",
    "\n",
    "data = model(Variable(torch.from_numpy(data)))\n",
    "data = minmax_scale.inverse_transform(data.detach().numpy())\n",
    "print(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = 'autoencoder.pth'\n",
    "torch.save(model.state_dict(), f'Models/{outfile}')\n",
    "filehandler = open('Objects/scalar','wb')\n",
    "pickle.dump(minmax_scale, filehandler)\n",
    "filehandler.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit",
   "language": "python",
   "name": "python37564biteac121e2b5f64df2ac86de1e25af1041"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
