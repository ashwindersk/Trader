\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{plain}
\providecommand \oddpage@label [2]{}
\citation{VA-fig}
\citation{DQN}
\citation{BSE}
\citation{BSG}
\citation{BC4}
\newlabel{chap:Executive Summary}{{}{vii}{Executive Summary}{chapter*.4}{}}
\citation{limit-order}
\citation{ZIP}
\citation{MGD}
\citation{vernon-smith}
\citation{Competitive-Equilibrium}
\citation{Gode-Sunder}
\citation{cliff-critique}
\citation{MGD}
\citation{IBM-experiments}
\citation{AA}
\citation{Fintech-lecture}
\citation{Fintech-lecture}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Contextual Background}{1}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{chap:context}{{1}{1}{Contextual Background}{chapter.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Introduction}{1}{section.1.1}}
\newlabel{section:Introduction}{{1.1}{1}{Introduction}{section.1.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}History of Research}{1}{section.1.2}}
\newlabel{section:History of Research}{{1.2}{1}{History of Research}{section.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Experimental Economics to Algorithmic Trading}{1}{subsection.1.2.1}}
\newlabel{subsection:Experimental Economics to Algorithmic Trading}{{1.2.1}{1}{Experimental Economics to Algorithmic Trading}{subsection.1.2.1}{}}
\citation{Deep-Learning-Revolution}
\citation{Sutton}
\citation{deep-learning-robots}
\citation{mx-banks-profit-breakdown}
\citation{quora-trading-hard}
\citation{computers-trade-more}
\citation{computers-trade-more}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}Developments in Artificial Intelligence}{3}{subsection.1.2.2}}
\newlabel{section:DevelopmentsAI}{{1.2.2}{3}{Developments in Artificial Intelligence}{subsection.1.2.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Motivations}{3}{section.1.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.1}Finance perspective}{3}{subsection.1.3.1}}
\newlabel{subsection:Finance perspective}{{1.3.1}{3}{Finance perspective}{subsection.1.3.1}{}}
\citation{deepmind-alpha-go-zero}
\citation{falcao}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.2}Computer science perspective}{4}{subsection.1.3.2}}
\newlabel{subsection:Computer Science perspective}{{1.3.2}{4}{Computer science perspective}{subsection.1.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.3}Furthering previous work}{4}{subsection.1.3.3}}
\newlabel{subsection:Furthering previous work}{{1.3.3}{4}{Furthering previous work}{subsection.1.3.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Central Challenges}{5}{section.1.4}}
\newlabel{section:Central Challenges}{{1.4}{5}{Central Challenges}{section.1.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Conclusion}{5}{section.1.5}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Technical Background}{7}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{chap:technical}{{2}{7}{Technical Background}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}The Core Problem}{7}{section.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}The Limit Order Book}{7}{subsection.2.1.1}}
\newlabel{subsection:The Limit Order Book}{{2.1.1}{7}{The Limit Order Book}{subsection.2.1.1}{}}
\newlabel{Technical:LOB}{{2.1.1}{7}{The Limit Order Book}{subsection.2.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces A graphical representation of a Limit Order Book, reproduced from Cliff (2018)\relax }}{7}{figure.caption.9}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:Lob}{{2.1}{7}{A graphical representation of a Limit Order Book, reproduced from Cliff (2018)\relax }{figure.caption.9}{}}
\newlabel{microprice}{{2.1}{8}{The Limit Order Book}{equation.2.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces A graphical representation of a Limit Order Book, reproduced from Cliff (2018)\relax }}{8}{figure.caption.10}}
\newlabel{fig:LobPost}{{2.2}{8}{A graphical representation of a Limit Order Book, reproduced from Cliff (2018)\relax }{figure.caption.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Proprietary trader's Objective}{9}{subsection.2.1.2}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Traditional Sales Trader Solutions}{9}{section.2.2}}
\newlabel{section:Traditional Sales Trader Solutions}{{2.2}{9}{Traditional Sales Trader Solutions}{section.2.2}{}}
\citation{MDP-demystified}
\citation{rearrange-value-function}
\citation{david-silver-teaching}
\citation{what-is-RL}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Reinforcement Learning}{10}{section.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}What is Reinforcement Learning?}{10}{subsection.2.3.1}}
\newlabel{subsection:What is Reinforcement Learning?}{{2.3.1}{10}{What is Reinforcement Learning?}{subsection.2.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Architecture of Reinforcement Learning Environments\relax }}{10}{figure.caption.11}}
\newlabel{fig:RL-arch}{{\caption@xref {fig:RL-arch}{ on input line 581}}{10}{What is Reinforcement Learning?}{figure.caption.11}{}}
\citation{rearrange-value-function}
\newlabel{discount-rewards}{{2.3}{11}{What is Reinforcement Learning?}{equation.2.3.3}{}}
\newlabel{expected-discounted-rewards}{{2.4}{11}{What is Reinforcement Learning?}{equation.2.3.4}{}}
\newlabel{expected-discounted-rewards-rephrased}{{2.5}{11}{What is Reinforcement Learning?}{equation.2.3.5}{}}
\citation{rearrange-value-function}
\citation{dynamic-programming}
\citation{optimal-control-theory-bellman}
\citation{MDP-theorem}
\newlabel{action-value}{{2.6}{12}{What is Reinforcement Learning?}{equation.2.3.6}{}}
\newlabel{bellman}{{2.7}{12}{What is Reinforcement Learning?}{equation.2.3.7}{}}
\newlabel{value-function-bellman}{{2.8}{12}{What is Reinforcement Learning?}{equation.2.3.8}{}}
\newlabel{action-value-bellman}{{2.9}{12}{What is Reinforcement Learning?}{equation.2.3.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Optimality}{12}{subsection.2.3.2}}
\newlabel{Optimality}{{2.3.2}{12}{Optimality}{subsection.2.3.2}{}}
\@writefile{toc}{\contentsline {paragraph}{Optimal Value Function.}{12}{section*.12}}
\@writefile{toc}{\contentsline {paragraph}{Optimal Action-Value Function.}{12}{section*.13}}
\@writefile{toc}{\contentsline {paragraph}{Optimal Policy.}{13}{section*.14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Challenges to Find Optimal Solutions}{13}{subsection.2.3.3}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Solving Reinforcement Learning}{13}{section.2.4}}
\newlabel{section:Solving Reinforcment Learning}{{2.4}{13}{Solving Reinforcement Learning}{section.2.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Model Free Prediction: Monte Carlo }{13}{subsection.2.4.1}}
\newlabel{Monte Carlo Prediction}{{2.4.1}{13}{Model Free Prediction: Monte Carlo}{subsection.2.4.1}{}}
\citation{TD-methods}
\newlabel{Monte Carlo Mean}{{2.10}{14}{Model Free Prediction: Monte Carlo}{equation.2.4.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Model Free Control: Monte Carlo}{14}{subsection.2.4.2}}
\newlabel{Monte Carlo Control}{{2.11}{14}{Model Free Control: Monte Carlo}{equation.2.4.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.3}Model Free: Temporal Difference Learning - TD(0)}{14}{subsection.2.4.3}}
\newlabel{subsection: Model Free:Temporal Difference Learning}{{2.4.3}{14}{Model Free: Temporal Difference Learning - TD(0)}{subsection.2.4.3}{}}
\newlabel{TD error}{{2.12}{14}{Model Free: Temporal Difference Learning - TD(0)}{equation.2.4.12}{}}
\newlabel{TD error}{{2.13}{14}{Model Free: Temporal Difference Learning - TD(0)}{equation.2.4.13}{}}
\newlabel{SARSA}{{2.14}{14}{Model Free: Temporal Difference Learning - TD(0)}{equation.2.4.14}{}}
\citation{VA-fig}
\citation{VA-fig}
\newlabel{Q-learning}{{2.15}{15}{Model Free: Temporal Difference Learning - TD(0)}{equation.2.4.15}{}}
\newlabel{SARSA}{{2.16}{15}{Model Free: Temporal Difference Learning - TD(0)}{equation.2.4.16}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.4}Value Function Approximation}{15}{subsection.2.4.4}}
\newlabel{subsection:value-function-approx}{{2.4.4}{15}{Value Function Approximation}{subsection.2.4.4}{}}
\newlabel{value-approx}{{2.17}{15}{Value Function Approximation}{equation.2.4.17}{}}
\newlabel{action-value-approx}{{2.18}{15}{Value Function Approximation}{equation.2.4.18}{}}
\citation{VA-fig}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Types of value approximators, reproduced from Silver \cite  {VA-fig}\relax }}{16}{figure.caption.15}}
\newlabel{fig:Approximators}{{2.4}{16}{Types of value approximators, reproduced from Silver \cite {VA-fig}\relax }{figure.caption.15}{}}
\newlabel{parameter-gradient}{{2.19}{16}{Value Function Approximation}{equation.2.4.19}{}}
\newlabel{MSE-supervised}{{2.20}{16}{Value Function Approximation}{equation.2.4.20}{}}
\citation{score-function}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.5}Policy Gradient}{17}{subsection.2.4.5}}
\newlabel{subsection:Policy Gradient}{{2.4.5}{17}{Policy Gradient}{subsection.2.4.5}{}}
\newlabel{Policy Gradient}{{2.21}{17}{Policy Gradient}{equation.2.4.21}{}}
\newlabel{Policy Gradient}{{2.22}{17}{Policy Gradient}{equation.2.4.22}{}}
\newlabel{Policy Gradient}{{2.23}{17}{Policy Gradient}{equation.2.4.23}{}}
\newlabel{Policy Gradient}{{2.24}{17}{Policy Gradient}{equation.2.4.24}{}}
\newlabel{Policy Gradient}{{2.26}{17}{Policy Gradient}{equation.2.4.26}{}}
\newlabel{Policy Gradient}{{2.27}{17}{Policy Gradient}{equation.2.4.27}{}}
\citation{DDPG}
\citation{DDPG-vs-DQN}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.6}Deep Deterministic Policy Gradient - (DDPG)}{18}{subsection.2.4.6}}
\newlabel{subsection:Deep Deterministic Policy Gradient}{{2.4.6}{18}{Deep Deterministic Policy Gradient - (DDPG)}{subsection.2.4.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Architecture Comparison: DQN vs DDPG, borrowed from\relax }}{19}{figure.caption.16}}
\newlabel{fig:DQN-DDPG-Arch}{{2.5}{19}{Architecture Comparison: DQN vs DDPG, borrowed from\relax }{figure.caption.16}{}}
\citation{Silver-theorem}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Training Actor with DDPG\relax }}{20}{figure.caption.17}}
\newlabel{fig:Training-Actor}{{2.6}{20}{Training Actor with DDPG\relax }{figure.caption.17}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.7}Discrete vs Continuous Action Spaces}{20}{subsection.2.4.7}}
\newlabel{subsection:Discrete Vs Continuous Action Spaces}{{2.4.7}{20}{Discrete vs Continuous Action Spaces}{subsection.2.4.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Summary}{21}{section.2.5}}
\citation{vernon-smith}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Project Execution}{23}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{chap:execution}{{3}{23}{Project Execution}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Origin}{23}{section.3.1}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}The Deeply Reinforced Trader}{23}{section.3.2}}
\newlabel{section:The Deeply Reinforced Trader}{{3.2}{23}{The Deeply Reinforced Trader}{section.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Training Environment}{23}{subsection.3.2.1}}
\citation{DeepLOB}
\newlabel{main-loop}{{3.1}{24}{Main loop to step through trading environment}{lstlisting.3.1}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {3.1}Main loop to step through trading environment}{24}{lstlisting.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Designing the State}{24}{subsection.3.2.2}}
\newlabel{BSG-Obs}{{3.2}{24}{BSG Environment Observation: LOB}{lstlisting.3.2}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {3.2}BSG Environment Observation: LOB}{24}{lstlisting.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Capturing LOB Data\relax }}{25}{figure.caption.18}}
\newlabel{fig:LOB-Snapshot}{{3.1}{25}{Capturing LOB Data\relax }{figure.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Architecture of Auto-Encoder\relax }}{26}{figure.caption.19}}
\newlabel{fig:AE-arch}{{\caption@xref {fig:AE-arch}{ on input line 1251}}{26}{Designing the State}{figure.caption.19}{}}
\newlabel{Final state}{{3.1}{26}{Designing the State}{equation.3.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Discretised Strategy}{27}{subsection.3.2.3}}
\newlabel{subsection:Discretised Strategy}{{3.2.3}{27}{Discretised Strategy}{subsection.3.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.4}Vanilla Reward}{27}{subsection.3.2.4}}
\newlabel{subsection:Vanilla Reward}{{3.2.4}{27}{Vanilla Reward}{subsection.3.2.4}{}}
\newlabel{Vanilla Reward}{{3.2}{27}{Vanilla Reward}{equation.3.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.5}The PG Vanilla Agent}{28}{subsection.3.2.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.6}Analysis and Evaluation of PG Vanilla}{28}{subsection.3.2.6}}
\newlabel{subsection:Analysis and Evaluation of PG Vanilla}{{3.2.6}{28}{Analysis and Evaluation of PG Vanilla}{subsection.3.2.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Total reward over 100 iterations of the PG-Vanilla trader in a market evenly populated with ZIC, ZIP and GVWY traders. \relax }}{28}{figure.caption.20}}
\newlabel{fig:PG-Vanilla-Reward}{{3.3}{28}{Total reward over 100 iterations of the PG-Vanilla trader in a market evenly populated with ZIC, ZIP and GVWY traders. \relax }{figure.caption.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces A plot of the number transactions the PG Vanilla agent engaged in during each episode \relax }}{29}{figure.caption.21}}
\newlabel{fig:PG-Vanilla-Num-Trades}{{3.4}{29}{A plot of the number transactions the PG Vanilla agent engaged in during each episode \relax }{figure.caption.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces A plot of the number of profitable trades and trades that incur a loss for the trader \relax }}{29}{figure.caption.22}}
\newlabel{fig:PG-Vanilla-Good-Vs-Bad}{{3.5}{29}{A plot of the number of profitable trades and trades that incur a loss for the trader \relax }{figure.caption.22}{}}
\citation{cobra-effect}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.7}Optimising The Reward Function}{30}{subsection.3.2.7}}
\newlabel{subsection:Optimising The Reward Function}{{3.2.7}{30}{Optimising The Reward Function}{subsection.3.2.7}{}}
\newlabel{Vanilla Reward}{{3.3}{30}{Optimising The Reward Function}{equation.3.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.8}Analysis of Optimised Reward System}{31}{subsection.3.2.8}}
\newlabel{subsection:Analysis and Evaluation of PG Vanilla}{{3.2.8}{31}{Analysis of Optimised Reward System}{subsection.3.2.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Total reward and balance over 373 iterations of the PG Agent with an optimised reward system \relax }}{31}{figure.caption.23}}
\newlabel{fig:PG-Optimised-Balance}{{3.6}{31}{Total reward and balance over 373 iterations of the PG Agent with an optimised reward system \relax }{figure.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces A plot of the number of profitable trades and trades that incur a loss for PG-Optimised \relax }}{32}{figure.caption.24}}
\newlabel{fig:PG-Optimised-Good-Vs-Bad}{{3.7}{32}{A plot of the number of profitable trades and trades that incur a loss for PG-Optimised \relax }{figure.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces A plot of the average profit and average loss of the PG-Optimised trader's trades over 373 iterations \relax }}{32}{figure.caption.25}}
\newlabel{fig:PG-Optimised-Loss-Vs-Profit}{{3.8}{32}{A plot of the average profit and average loss of the PG-Optimised trader's trades over 373 iterations \relax }{figure.caption.25}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.9}Continuous Actions}{34}{subsection.3.2.9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.10}The DDPG Agent}{34}{subsection.3.2.10}}
\newlabel{actor-forward-pass}{{3.3}{34}{Forward pass for the Actor Model}{lstlisting.3.3}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {3.3}Forward pass for the Actor Model}{34}{lstlisting.3.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.11}Analysis and Evaluation of DDPG Agent}{35}{subsection.3.2.11}}
\newlabel{subsection:Analysis and Evaluation of DDPG Agent}{{3.2.11}{35}{Analysis and Evaluation of DDPG Agent}{subsection.3.2.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces Total balance over 114 iterations of the DDPG trader with an optimised reward system \relax }}{35}{figure.caption.26}}
\newlabel{fig:DDPG-Balance}{{3.9}{35}{Total balance over 114 iterations of the DDPG trader with an optimised reward system \relax }{figure.caption.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces Total reward over 114 iterations of the DDPG trader with an optimised reward system \relax }}{36}{figure.caption.27}}
\newlabel{fig:DDPG-Good-Vs-Bad}{{3.10}{36}{Total reward over 114 iterations of the DDPG trader with an optimised reward system \relax }{figure.caption.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.11}{\ignorespaces A plot of the profitable vs negative trades for the DDPG trader over 114 iterations\relax }}{36}{figure.caption.28}}
\newlabel{fig:DDPG-Good-Vs-Bad}{{3.11}{36}{A plot of the profitable vs negative trades for the DDPG trader over 114 iterations\relax }{figure.caption.28}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.12}{\ignorespaces A plot of the average profit and average losses incurred from the DDPG trader's trades over 114 iterations \relax }}{37}{figure.caption.29}}
\newlabel{fig:DDPG-Average-Trade}{{3.12}{37}{A plot of the average profit and average losses incurred from the DDPG trader's trades over 114 iterations \relax }{figure.caption.29}{}}
\citation{sample-inefficient}
\citation{sample-solution}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.12}Sparsity in rewards}{38}{subsection.3.2.12}}
\newlabel{sparse rewards}{{3.4}{38}{Sampling experiences with a probability factor}{lstlisting.3.4}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {3.4}Sampling experiences with a probability factor}{38}{lstlisting.3.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.13}{\ignorespaces Total balance over 116 iterations of the DDPG-Sparsity trader with an optimised reward system \relax }}{39}{figure.caption.30}}
\newlabel{fig:DDPG-Balance}{{3.13}{39}{Total balance over 116 iterations of the DDPG-Sparsity trader with an optimised reward system \relax }{figure.caption.30}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.14}{\ignorespaces Total reward over 116 iterations of the DDPG-Sparsity trader with an optimised reward system \relax }}{40}{figure.caption.31}}
\newlabel{fig:DDPG-Sparsity-Reward}{{3.14}{40}{Total reward over 116 iterations of the DDPG-Sparsity trader with an optimised reward system \relax }{figure.caption.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.15}{\ignorespaces A plot of the profitable vs negative trades for the DDPG-Sparsity trader over 116 iterations\relax }}{40}{figure.caption.32}}
\newlabel{fig:DDPG-Sparsity-Good-Vs-Bad}{{3.15}{40}{A plot of the profitable vs negative trades for the DDPG-Sparsity trader over 116 iterations\relax }{figure.caption.32}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.16}{\ignorespaces A plot of the average profit and average losses incurred from the DDPG-Sparsity trader's trades over 116 iterations \relax }}{41}{figure.caption.33}}
\newlabel{fig:DDPG-Sparsity-Average-Trade}{{3.16}{41}{A plot of the average profit and average losses incurred from the DDPG-Sparsity trader's trades over 116 iterations \relax }{figure.caption.33}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Conclusion}{43}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{chap:conclusion}{{4}{43}{Conclusion}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Overview}{43}{section.4.1}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Project Status}{43}{section.4.2}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Future Work}{44}{section.4.3}}
\citation{*}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Exploration of State Space Design}{45}{subsection.4.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Regression Models}{45}{subsection.4.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}Increase explorative power}{45}{subsection.4.3.3}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Last Words}{45}{section.4.4}}
\bibdata{dissertation.bib}
\bibcite{MDP-demystified}{1}
\bibcite{sample-solution}{2}
\bibcite{cobra-effect}{3}
\bibcite{computers-trade-more}{4}
\bibcite{BSE}{5}
\bibcite{cliff-critique}{6}
\bibcite{Fintech-lecture}{7}
\bibcite{ZIP}{8}
\bibcite{score-function}{9}
\bibcite{IBM-experiments}{10}
\bibcite{dynamic-programming}{11}
\bibcite{BSG}{12}
\bibcite{falcao}{13}
\bibcite{BC4}{14}
\bibcite{MGD}{15}
\bibcite{rearrange-value-function}{16}
\bibcite{optimal-control-theory-bellman}{17}
\bibcite{quora-trading-hard}{18}
\bibcite{limit-order}{19}
\bibcite{deep-learning-robots}{20}
\bibcite{Competitive-Equilibrium}{21}
\bibcite{DDPG}{22}
\bibcite{TD-methods}{23}
\bibcite{DDPG-vs-DQN}{24}
\bibcite{DQN}{25}
\bibcite{what-is-RL}{26}
\bibcite{Sutton}{27}
\bibcite{Deep-Learning-Revolution}{28}
\bibcite{VA-fig}{29}
\bibcite{david-silver-teaching}{30}
\bibcite{MDP-theorem}{31}
\bibcite{deepmind-alpha-go-zero}{32}
\bibcite{Silver-theorem}{33}
\bibcite{DeepLOB}{34}
\bibcite{vernon-smith}{35}
\bibcite{sample-inefficient}{36}
\bibcite{mx-banks-profit-breakdown}{37}
\bibcite{Gode-Sunder}{38}
\bibcite{AA}{39}
