\contentsline {chapter}{\numberline {1}Contextual Background}{1}{chapter.1}
\contentsline {section}{\numberline {1.1}Introduction}{1}{section.1.1}
\contentsline {section}{\numberline {1.2}History of Research}{1}{section.1.2}
\contentsline {subsection}{\numberline {1.2.1}Experimental Economics to Algorithmic Trading}{1}{subsection.1.2.1}
\contentsline {subsection}{\numberline {1.2.2}Developments in Artificial Intelligence}{3}{subsection.1.2.2}
\contentsline {section}{\numberline {1.3}Motivations}{3}{section.1.3}
\contentsline {subsection}{\numberline {1.3.1}Finance perspective}{3}{subsection.1.3.1}
\contentsline {subsection}{\numberline {1.3.2}Computer science perspective}{4}{subsection.1.3.2}
\contentsline {subsection}{\numberline {1.3.3}Furthering previous work}{4}{subsection.1.3.3}
\contentsline {section}{\numberline {1.4}Central Challenges}{5}{section.1.4}
\contentsline {section}{\numberline {1.5}Conclusion}{5}{section.1.5}
\contentsline {chapter}{\numberline {2}Technical Background}{7}{chapter.2}
\contentsline {section}{\numberline {2.1}The Core Problem}{7}{section.2.1}
\contentsline {subsection}{\numberline {2.1.1}The Limit Order Book}{7}{subsection.2.1.1}
\contentsline {subsection}{\numberline {2.1.2}Proprietary trader's Objective}{9}{subsection.2.1.2}
\contentsline {section}{\numberline {2.2}Traditional Sales Trader Solutions}{9}{section.2.2}
\contentsline {section}{\numberline {2.3}Reinforcement Learning}{10}{section.2.3}
\contentsline {subsection}{\numberline {2.3.1}What is Reinforcement Learning?}{10}{subsection.2.3.1}
\contentsline {subsection}{\numberline {2.3.2}Optimality}{12}{subsection.2.3.2}
\contentsline {paragraph}{Optimal Value Function.}{12}{section*.12}
\contentsline {paragraph}{Optimal Action-Value Function.}{12}{section*.13}
\contentsline {paragraph}{Optimal Policy.}{13}{section*.14}
\contentsline {subsection}{\numberline {2.3.3}Challenges to Find Optimal Solutions}{13}{subsection.2.3.3}
\contentsline {section}{\numberline {2.4}Solving Reinforcement Learning}{13}{section.2.4}
\contentsline {subsection}{\numberline {2.4.1}Model Free Prediction: Monte Carlo }{13}{subsection.2.4.1}
\contentsline {subsection}{\numberline {2.4.2}Model Free Control: Monte Carlo}{14}{subsection.2.4.2}
\contentsline {subsection}{\numberline {2.4.3}Model Free: Temporal Difference Learning - TD(0)}{14}{subsection.2.4.3}
\contentsline {subsection}{\numberline {2.4.4}Value Function Approximation}{15}{subsection.2.4.4}
\contentsline {subsection}{\numberline {2.4.5}Policy Gradient}{17}{subsection.2.4.5}
\contentsline {subsection}{\numberline {2.4.6}Deep Deterministic Policy Gradient - (DDPG)}{18}{subsection.2.4.6}
\contentsline {subsection}{\numberline {2.4.7}Discrete vs Continuous Action Spaces}{20}{subsection.2.4.7}
\contentsline {section}{\numberline {2.5}Summary}{21}{section.2.5}
\contentsline {chapter}{\numberline {3}Project Execution}{23}{chapter.3}
\contentsline {section}{\numberline {3.1}Origin}{23}{section.3.1}
\contentsline {section}{\numberline {3.2}The Deeply Reinforced Trader}{23}{section.3.2}
\contentsline {subsection}{\numberline {3.2.1}Training Environment}{23}{subsection.3.2.1}
\contentsline {subsection}{\numberline {3.2.2}Designing the State}{24}{subsection.3.2.2}
\contentsline {subsection}{\numberline {3.2.3}Discretised Strategy}{27}{subsection.3.2.3}
\contentsline {subsection}{\numberline {3.2.4}Vanilla Reward}{27}{subsection.3.2.4}
\contentsline {subsection}{\numberline {3.2.5}The PG Vanilla Agent}{28}{subsection.3.2.5}
\contentsline {subsection}{\numberline {3.2.6}Analysis and Evaluation of PG Vanilla}{28}{subsection.3.2.6}
\contentsline {subsection}{\numberline {3.2.7}Optimising The Reward Function}{30}{subsection.3.2.7}
\contentsline {subsection}{\numberline {3.2.8}Analysis of Optimised Reward System}{31}{subsection.3.2.8}
\contentsline {subsection}{\numberline {3.2.9}Continuous Actions}{34}{subsection.3.2.9}
\contentsline {subsection}{\numberline {3.2.10}The DDPG Agent}{34}{subsection.3.2.10}
\contentsline {subsection}{\numberline {3.2.11}Analysis and Evaluation of DDPG Agent}{35}{subsection.3.2.11}
\contentsline {subsection}{\numberline {3.2.12}Sparsity in rewards}{38}{subsection.3.2.12}
\contentsline {chapter}{\numberline {4}Conclusion}{43}{chapter.4}
\contentsline {section}{\numberline {4.1}Overview}{43}{section.4.1}
\contentsline {section}{\numberline {4.2}Project Status}{43}{section.4.2}
\contentsline {section}{\numberline {4.3}Future Work}{44}{section.4.3}
\contentsline {subsection}{\numberline {4.3.1}Exploration of State Space Design}{45}{subsection.4.3.1}
\contentsline {subsection}{\numberline {4.3.2}Regression Models}{45}{subsection.4.3.2}
\contentsline {subsection}{\numberline {4.3.3}Increase explorative power}{45}{subsection.4.3.3}
\contentsline {section}{\numberline {4.4}Last Words}{45}{section.4.4}
